# WebScraping---Thesis

GitHub is a web-based platform that provides version control and collaboration features. You can store your code on GitHub, share it with others, and keep track of changes to the code over time. This can be especially helpful if you're working on a web scraping project that involves multiple contributors or if you want to store your code in a secure and accessible place.

PubMed is a database of biomedical literature maintained by the National Library of Medicine (NLM) at the National Institutes of Health (NIH). While web scraping can be a useful tool for extracting data from websites, it is important to consider the terms of use for the websites you scrape.

According to the PubMed Central (PMC) Data Use Policy, the NLM encourages the use of its data for text and data mining purposes, but it requires that users follow certain guidelines. For example, users must:

Provide appropriate acknowledgment of the source of the data
Not use the data for commercial purposes
Not redistribute the data to others
Limit their use of the data to the minimum necessary to achieve their research goals
While web scraping can be a useful tool for accessing the data in PubMed, it is important to be mindful of these guidelines and to ensure that your use of the data complies with the PMC Data Use Policy. If you are uncertain about whether a specific use of the data is permitted, you may wish to consult the PMC Data Use Policy or contact the NLM directly for guidance.
